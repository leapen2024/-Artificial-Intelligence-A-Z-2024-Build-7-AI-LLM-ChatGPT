{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL/REvlfDrL8FKV6bFgGZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leapen2024/-Artificial-Intelligence-A-Z-2024-Build-7-AI-LLM-ChatGPT/blob/main/QLearningArthurJuliani.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTzDVnh8Nsdk",
        "outputId": "3b751af3-1264-46a8-9c0c-44b13db188f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score over time: 0.381\n",
            "Final Q-Table Values\n",
            "[[2.70301332e-03 4.01143869e-02 3.68902226e-03 2.73064328e-03]\n",
            " [4.73408232e-04 8.65214772e-05 8.91396501e-05 2.25256020e-02]\n",
            " [9.24973465e-04 4.05425929e-04 5.04933487e-04 1.33421931e-02]\n",
            " [4.29189847e-04 1.55871306e-05 2.01758741e-05 1.16409848e-02]\n",
            " [4.19775638e-02 5.18053499e-04 2.19100560e-03 4.48627324e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [3.27806357e-02 1.47825596e-05 5.29339720e-06 3.49485374e-05]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [7.14126409e-04 3.97491100e-04 2.36599134e-03 2.20994252e-01]\n",
            " [1.99630173e-03 6.48012399e-01 5.99333781e-04 1.81307082e-03]\n",
            " [1.99233653e-01 3.07777050e-04 1.56079715e-04 5.50467025e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 7.90520697e-01 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.67730857e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Q-Table Learning\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "#Load the environment\n",
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "#Implement Q-Table learning algorithm\n",
        "#Initialize table with all zeros\n",
        "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
        "# Set learning parameters\n",
        "lr = .8\n",
        "y = .95\n",
        "num_episodes = 2000\n",
        "#create lists to contain total rewards and steps per episode\n",
        "#jList = []\n",
        "rList = []\n",
        "for i in range(num_episodes):\n",
        "    #Reset environment and get first new observation\n",
        "    s = env.reset()\n",
        "    rAll = 0\n",
        "    d = False\n",
        "    j = 0\n",
        "    #The Q-Table learning algorithm\n",
        "    while j < 99:\n",
        "        j+=1\n",
        "        #Choose an action by greedily (with noise) picking from Q table\n",
        "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
        "        #Get new state and reward from environment\n",
        "        s1,r,d,_ = env.step(a)\n",
        "        #Update Q-Table with new knowledge\n",
        "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n",
        "        rAll += r\n",
        "        s = s1\n",
        "        if d == True:\n",
        "            break\n",
        "    #jList.append(j)\n",
        "    rList.append(rAll)\n",
        "print (\"Score over time: \" +  str(sum(rList)/num_episodes))\n",
        "print (\"Final Q-Table Values\")\n",
        "print (Q)"
      ]
    }
  ]
}